# -*- coding: utf-8 -*-
# """model training.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1PBBQtX5_k_vQJsEZVRWRnfVwhStCGBan
# """

# from datasets import load_dataset
# ds = load_dataset("DarshanaS/IndicAccentDb")

# print(ds["train"][0])

# import numpy as np

# # example: load one audio
# sample = ds["train"][0]
# audio = sample["audio"]["array"]
# sr = sample["audio"]["sampling_rate"]

# # extract MFCCs
# import librosa
# mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
# print(mfcc.shape)

# import numpy as np
# import pandas as pd

# mfcc_data = []

# for s in ds["train"]:
#     y = s["audio"]["array"]
#     sr = s["audio"]["sampling_rate"]
#     mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
#     mfcc_mean = mfcc.mean(axis=1)
#     mfcc_data.append(mfcc_mean)

# df = pd.DataFrame(mfcc_data)
# df.to_csv("indic_accent_mfcc.csv", index=False)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import sklearn

df = pd.read_csv('label+mfcc dataset.csv')

df.head()

df.isnull().sum()

count_classes = pd.value_counts(df['label'], sort = True)
count_classes.plot(kind = 'bar', rot=0)
plt.title("Before Upsampling")
plt.xticks()
plt.xlabel("language")
plt.ylabel("Frequency")

df['label'].value_counts()

from imblearn.over_sampling import SMOTE

x = df.drop(['label'], axis=1)
y = df.label
x.head()

x.shape, y.shape
smk = SMOTE(random_state=15)
x_res,y_res=smk.fit_resample(x, y)

x_res.shape, y_res.shape

y_res.value_counts()

count_classes = pd.value_counts(y_res, sort = True)
count_classes.plot(kind = 'bar', rot=0)
plt.title("After Upsampling")
plt.xticks()
plt.xlabel("language")
plt.ylabel("Frequency")

y_res, labels = pd.factorize(y_res)

print(labels)

y.head()

#Standarization
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
x.iloc[:,:] = scaler.fit_transform(x.iloc[:,:])

x.head()

"""train and test split"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_res, y_res, test_size=0.30, random_state=5)

print(x_train.shape)
print(x_test.shape)
print(y_train.shape)
print(y_test.shape)

"""ml algo implement"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(x_train,y_train)
knn_accuracy = knn.score(x_test, y_test)
knn_accuracy

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=5)
dt.fit(x_train,y_train)
pred_dt = dt.predict(x_test)
dt_accuracy=dt.score(x_test, y_test)
dt_accuracy

from sklearn.svm import SVC
svc= SVC(random_state=5)
svc.fit(x_train,y_train)
svc_accuracy = svc.score(x_test, y_test)
svc_accuracy

#Random Forest with best accuracy
from sklearn.ensemble import RandomForestClassifier
randf = RandomForestClassifier(random_state=5)
randf.fit(x_train,y_train)
pred_randf = randf.predict(x_test)
#pred_randf_with_categorical_value = le.inverse_transform(pred_randf)
#print(pred_randf_with_categorical_value)
randf_accuracy = randf.score(x_test, y_test)
randf_accuracy

print(pred_randf.shape)

from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression(random_state=5)
logreg.fit(x_train, y_train)
logreg_accuracy=logreg.score(x_test, y_test)
logreg_accuracy

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(x_train, y_train)
nb_accuracy=nb.score(x_test, y_test)
nb_accuracy

"""saving ml model"""

import joblib as jb

#Saving models using Joblib
jb.dump(knn,'knn')
jb.dump(dt,'dt')
jb.dump(svc,'svc')
jb.dump(randf,'randf')
jb.dump(logreg,'logreg')
jb.dump(nb,'nb')

#Loading those saved models
import joblib as jb
knn_default = jb.load('knn')
dt_default =  jb.load('dt')
svc_default = jb.load('svc')
randf_default =  jb.load('randf')
logreg_default =  jb.load('logreg')
nb_default =  jb.load('nb')

#Printing accuracy from the saved model files
print("KNN accuracy           : ", knn_default.score(x_test,y_test))
print("Decision Tree accuracy : ", dt_default.score(x_test,y_test))
print("Support Vector Machine : ", svc_default.score(x_test,y_test))
print("Random Forest accuracy : ", randf_default.score(x_test,y_test))
print("Logistic Regression    : ", logreg_default.score(x_test,y_test))
print("Naive Bayes accuracy   : ", nb_default.score(x_test,y_test))

"""model performance"""

d = {'Algorithm': ['K Nearest Neighbors', 'Support Vector Machine','Decision Tree',
                   'Random Forest','Logistic Regression','Naive Bayes'],
     'Accuracy (in percent)': [91.91,85.85,90.23,95.28,83.50,76.09]}
df_accuracy = pd.DataFrame(data=d)
print(df_accuracy)

plt.figure(figsize=(7,6))
plt.title('Accuracy Comparison',fontsize=14, pad = 10.0)
p = sns.barplot(x="Algorithm", y="Accuracy (in percent)", data=df_accuracy,palette='hot',edgecolor=sns.color_palette('dark',7))
plt.xticks(rotation=90)
p.set_xlabel('Algorithm', fontsize=14)
p.set_ylabel('Accuracy (in percent)', fontsize=14)
p.bar_label(p.containers[0])
#plt.savefig('Accuracy Comparison', dpi=300);

from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_curve
from sklearn.multiclass import OneVsRestClassifier

cf_matrix = confusion_matrix(y_test,pred_randf)
cf_matrix

import seaborn as sns
cf_matrix = pd.crosstab(labels[y_test],labels[pred_randf])
fig = plt.subplots(figsize=(7,5))
s = sns.heatmap(cf_matrix, linewidths=1, annot=True)
s.set_xlabel('Predicted', labelpad=8.0, fontsize=14)
s.set_ylabel('Truth', labelpad=8.0, fontsize=14)
#plt.savefig('Confusion Matrix',dpi=300);
plt.yticks(rotation=0)

print(classification_report(y_test,pred_randf,target_names=labels))

clf = OneVsRestClassifier(randf)
clf.fit(x_train, y_train)
pred = clf.predict(x_test)
pred_prob = clf.predict_proba(x_test)

fpr = {}
tpr = {}
thresh ={}

n_class = 6
for i in range(n_class):
    fpr[i], tpr[i], thresh[i] = roc_curve(y_test, pred_prob[:,i], pos_label=i)

plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='andhra pradesh vs Rest')
plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='gujrat vs Rest')
plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='jharkhand vs Rest')
plt.plot(fpr[3], tpr[3], linestyle='--',color='red', label='karnataka vs Rest')
plt.plot(fpr[4], tpr[4], linestyle='--',color='lawngreen', label='kerala vs Rest')
plt.plot(fpr[5], tpr[5], linestyle='--',color='black', label='tamil nadu vs Rest')
plt.title('Multiclass ROC curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive rate')
plt.legend(loc='best')

from sklearn.metrics import accuracy_score

y_train_pred = clf.predict(x_train)
y_test_pred = clf.predict(x_test)

train_acc = accuracy_score(y_train, y_train_pred)
test_acc = accuracy_score(y_test, y_test_pred)

print("Train accuracy:", train_acc)
print("Test accuracy:", test_acc)

"""# We will use Random Forest model because its got the best scores overall."""

